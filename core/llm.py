"""
LLM Manager Module - Memory-Free Version
Handles OpenAI API interactions with robust custom memory system
"""

import random
import streamlit as st
from openai import OpenAI
import io
import re
from typing import Optional, List, Dict, Literal
from pydantic import BaseModel, Field
import logging
import json
import sqlite3
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def normalize_company_name(name: str) -> str:
    """Normalize company names for consistent memory storage and search."""
    if not name:
        return ""
    name = name.lower()
    name = " ".join(name.split())
    name = re.sub(r'[^\w\s]', '', name)
    return name

# -----------------------------
# Pydantic Models for Structured Outputs
# -----------------------------

class IntentClassification(BaseModel):
    intent: Literal["GREETING", "DATABASE", "GENERAL_HAJJ", "NEEDS_INFO"] = Field(
        description="The classified intent of the user's message"
    )
    confidence: float = Field(
        ge=0.0, le=1.0,
        description="Confidence score of the classification (0-1)"
    )
    reasoning: str = Field(
        description="Brief explanation of why this intent was chosen"
    )


class SQLQueryGeneration(BaseModel):
    sql_query: Optional[str] = Field(None, description="The generated SQL SELECT query, or None if no safe query can be generated")
    query_type: Literal["simple", "aggregation", "complex", "no_sql"] = Field(description="Type of query generated")
    filters_applied: List[str] = Field(default_factory=list, description="List of filters or conditions applied in the query")
    explanation: str = Field(description="Human-readable explanation of what the query does")
    safety_checked: bool = Field(description="Whether the query passed safety validation")


class QuerySummary(BaseModel):
    summary: str = Field(description="Natural language summary of the query results")
  

class GreetingResponse(BaseModel):
    greeting: str = Field(description="The friendly greeting message")
    tone: Literal["formal", "casual", "warm"] = Field(description="Tone of the greeting")
    includes_offer_to_help: bool = Field(description="Whether the greeting includes an offer to help")
    
    
class NEEDSInfoResponse(BaseModel):
    needs_info: str = Field(description="The message asking user for more specific information")
    suggestions: List[str] = Field(default_factory=list, description="List of example queries the user could try")
    missing_info: List[str] = Field(default_factory=list, description="List of specific information pieces needed")
    sample_query: str = Field(description="An example of a well-formed query")
    user_lang: Literal["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"] = Field(description="Language to respond in")


class LLMManager:
    """Ø¨Ø¯ÙŠÙ„ Ù…Ø¶Ù…ÙˆÙ† Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø¯ÙˆÙ† Langchain"""
    
    def __init__(self, max_history=20):
        self.max_history = max_history
        self._init_session_state()
    
    def _init_session_state(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        if "chat_memory" not in st.session_state:
            st.session_state.chat_memory = []
        if "last_company_name" not in st.session_state:
            st.session_state.last_company_name = ""
        if "conversation_context" not in st.session_state:
            st.session_state.conversation_context = []
    
    def add_message(self, role: str, content: str):
        """Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ø°Ø§ÙƒØ±Ø©"""
        self._init_session_state()
        message = {"role": role, "content": content, "timestamp": datetime.now().isoformat()}
        st.session_state.chat_memory.append(message)
        
        # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        if len(st.session_state.chat_memory) > self.max_history:
            st.session_state.chat_memory = st.session_state.chat_memory[-self.max_history:]
    
    def get_recent_messages(self, limit: int = 10) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø§Ù„Ø±Ø³Ø§Ø¦Ù„"""
        self._init_session_state()
        return st.session_state.chat_memory[-limit:] if st.session_state.chat_memory else []
    
    def get_conversation_context(self, limit: Optional[int] = None) -> List[Dict[str, str]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ)"""
        messages = self.get_recent_messages(limit or self.max_history)
        return [{"role": msg["role"], "content": msg["content"]} for msg in messages]
    
    def store_last_company(self, company_name: str):
        """ØªØ®Ø²ÙŠÙ† Ø¢Ø®Ø± Ø´Ø±ÙƒØ© ØªÙ… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù†Ù‡Ø§"""
        if company_name:
            normalized_name = normalize_company_name(company_name)
            st.session_state.last_company_name = normalized_name
    
    def get_last_company(self) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø´Ø±ÙƒØ©"""
        return st.session_state.get("last_company_name", "")
    
    def clear_memory(self):
        """Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ±)"""
        st.session_state.chat_memory = []
        st.session_state.last_company_name = ""
        st.session_state.conversation_context = []


class LLMManager:
    """Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¹ Ø°Ø§ÙƒØ±Ø© Ù…Ø¶Ù…ÙˆÙ†Ø©"""
    
    def __init__(self):
        self.memory = LLMManager(max_history=20)
        self.client = self._init_openai_client()
        
        # Ø£ØµÙˆØ§Øª TTS Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©
        self.voice_map = {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "onyx",
            "English": "alloy"
        }
    
    def _init_openai_client(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ OpenAI"""
        api_key = st.secrets.get("key")
        if not api_key:
            logger.error("OpenAI API key not found")
            st.warning("âš ï¸ OpenAI API key missing in Streamlit secrets")
            st.stop()
        return OpenAI(api_key=api_key)
    
    def store_last_company(self, company_name: str):
        """ØªØ®Ø²ÙŠÙ† Ø¢Ø®Ø± Ø´Ø±ÙƒØ© (ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø©)"""
        self.memory.store_last_company(company_name)
    
    def get_last_company(self) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø´Ø±ÙƒØ© (ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø©)"""
        return self.memory.get_last_company()
    
    def add_user_message(self, user_input: str):
        """Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ù…Ø³ØªØ®Ø¯Ù…"""
        self.memory.add_message("user", user_input)
    
    def add_assistant_message(self, assistant_reply: str):
        """Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯"""
        self.memory.add_message("assistant", assistant_reply)
    
    def build_chat_context(self, limit: Optional[int] = None) -> List[Dict[str, str]]:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø©)"""
        return self.memory.get_conversation_context(limit)
    
    def ask(self, user_input: str) -> str:
        """
        Ø¨Ø¯ÙŠÙ„ Ø¹Ù† conversation.predict Ù…Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¶Ù…ÙˆÙ†Ø©
        """
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        context_messages = self.build_chat_context(limit=10)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        messages = []
        
        # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³ÙŠØ§Ù‚
        for msg in context_messages:
            messages.append({"role": msg["role"], "content": msg["content"]})
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        messages.append({"role": "user", "content": user_input})
        
        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI Ù…Ø¨Ø§Ø´Ø±Ø©
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.4,
                max_tokens=1000
            )
            
            assistant_reply = response.choices[0].message.content.strip()
            
            # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.add_user_message(user_input)
            self.add_assistant_message(assistant_reply)
            
            return assistant_reply
            
        except Exception as e:
            logger.error(f"Ask method failed: {e}")
            return "I apologize, but I encountered an error. Please try again."
    
    def detect_intent(self, user_input: str, language: str) -> Dict:
        """
        ÙƒØ´Ù Ø§Ù„Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¶Ù…ÙˆÙ†Ø©
        """
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        context = self.build_chat_context(limit=5)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        
        intent_prompt = f"""
        You are a fraud-prevention assistant for Hajj pilgrims.
        
        ğŸ“‹ Classify this message into ONE of four categories:
        
        1ï¸âƒ£ GREETING: Greetings, hello, hi, how are you, salam, Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…, Ù…Ø±Ø­Ø¨Ø§
        
        2ï¸âƒ£ DATABASE: Questions about verifying specific Hajj agencies, authorization, company details
        
        3ï¸âƒ£ GENERAL_HAJJ: General Hajj-related questions (rituals, requirements, procedures)
        
        4ï¸âƒ£ NEEDS_INFO: Vague messages that need more details
        
        Conversation Context:
        {context_text}
        
        Message: {user_input}
        
        Extract any company name mentioned and classify the intent.
        Return JSON with: intent, confidence, reasoning, extracted_company
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an intent classification expert. Always return valid JSON."},
                    {"role": "user", "content": intent_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            intent_data = json.loads(response.choices[0].message.content)
            logger.info(f"Intent detected: {intent_data.get('intent')}")
            
            # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø´Ø±ÙƒØ© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
            extracted_company = intent_data.get('extracted_company')
            if extracted_company:
                self.store_last_company(extracted_company)
            
            return intent_data
            
        except Exception as e:
            logger.error(f"Intent detection failed: {e}")
            return self._fallback_intent_detection(user_input)
    
    def _fallback_intent_detection(self, user_input: str) -> Dict:
        """ÙƒØ´Ù Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        ui = user_input.lower()
        
        if any(g in ui for g in ["hello", "hi", "salam", "Ø§Ù„Ø³Ù„Ø§Ù…", "Ù…Ø±Ø­Ø¨Ø§"]):
            intent = "GREETING"
        elif any(k in ui for k in ["company", "agency", "Ù…Ø¹ØªÙ…Ø¯", "Ø´Ø±ÙƒØ§Øª", "authorized", "ÙˆÙƒØ§Ù„Ø©"]):
            intent = "DATABASE" if len(ui.split()) >= 4 else "NEEDS_INFO"
        else:
            intent = "GENERAL_HAJJ"
        
        return {
            "intent": intent,
            "confidence": 0.7,
            "reasoning": "Determined by keyword matching (fallback)",
            "extracted_company": ""
        }
    
    def generate_greeting(self, user_input: str, language: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØ­ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        context = self.build_chat_context(limit=5)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        
        system_prompt = """
        You are a friendly Hajj and fraud prevention assistant.
        - Respond in Arabic if the user input contains Arabic text; otherwise, respond in English.
        - Generate a short, warm, natural greeting (max 3 sentences)
        - Acknowledge the user's greeting and express willingness to help
        - Mention you can help verify Hajj companies
        - Use emojis appropriately
        """
        
        try:
            prompt = f"{system_prompt}\nConversation Context:\n{context_text}\n\nUser says: {user_input}"
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=200
            )
            
            greeting = response.choices[0].message.content.strip()
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.add_user_message(user_input)
            self.add_assistant_message(greeting)
            
            return greeting
            
        except Exception as e:
            logger.error(f"Greeting generation failed: {e}")
            return "Hello! ğŸ‘‹ How can I help you today?" if language != "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…! ğŸ‘‹ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"
    
    def generate_general_answer(self, user_input: str, language: str) -> str:
        """Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        context = self.build_chat_context(limit=5)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        
        system_prompt = """You are a helpful assistant specialized in Hajj information. 
        Be concise, factual, and helpful. Focus on practical information.
        Detect if the user's question is in Arabic or English, and respond in the same language.
        You are designed to protect pilgrims from scams and help them verify hajj agencies authorized from Ministry of Hajj and Umrah
        Avoid religious rulings or fatwa - stick to practical guidance."""
        
        try:
            prompt = f"{system_prompt}\nConversation Context:\n{context_text}\n\nUser asks: {user_input}"
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4,
                max_tokens=500
            )
            
            answer = response.choices[0].message.content.strip()
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.add_user_message(user_input)
            self.add_assistant_message(answer)
            
            return answer
            
        except Exception as e:
            logger.error(f"General answer generation failed: {e}")
            return "I encountered an error. Please try rephrasing your question." if language != "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ."
    
    def generate_sql(self, user_input: str, language: str) -> Optional[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        context = self.build_chat_context(limit=3)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        
        sql_prompt = self._get_sql_system_prompt(language) + f"\n\nConversation Context:\n{context_text}\n\nUser Question: {user_input}"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a SQL expert. Always return valid JSON."},
                    {"role": "user", "content": sql_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            sql_data = json.loads(response.choices[0].message.content)
            
            return {
                "sql_query": sql_data.get("sql_query"),
                "query_type": sql_data.get("query_type"),
                "filters": sql_data.get("filters_applied", []),
                "explanation": sql_data.get("explanation")
            } if sql_data.get("sql_query") and sql_data.get("safety_checked") else None
            
        except Exception as e:
            logger.error(f"SQL generation failed: {e}")
            return None
    
    def generate_summary(self, user_input: str, language: str, row_count: int, sample_rows: List[Dict]) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        if row_count == 0:
            return {"summary": "No results found." if language == "English" else "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬."}
        
        # ØªØ®Ø²ÙŠÙ† Ø¢Ø®Ø± Ø´Ø±ÙƒØ© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        first_row = sample_rows[0]
        last_agency = first_row.get("hajj_company_en") or first_row.get("hajj_company_ar")
        if last_agency:
            self.store_last_company(last_agency)
        
        context = self.build_chat_context(limit=3)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        data_preview = json.dumps(sample_rows[:50], ensure_ascii=False)
        
        summary_prompt = f"""
        You are a multilingual fraud-prevention and travel assistant for Hajj agencies.
        
        ğŸš¨ CRITICAL LANGUAGE RULE:
        - Respond in {language} ONLY
        
        Conversation Context:
        {context_text}
        
        User question: {user_input}
        Data: {data_preview}
        
        Generate a friendly, professional summary in {language}.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"You are a helpful assistant. Respond in {language} only."},
                    {"role": "user", "content": summary_prompt}
                ],
                temperature=0.4,
                max_tokens=800
            )
            
            summary = response.choices[0].message.content.strip()
            
            return {"summary": summary}
            
        except Exception as e:
            logger.error(f"Summary generation failed: {e}")
            return {"summary": f"ğŸ“Š Found {row_count} matching records."}
    
    def ask_for_more_info(self, user_input: str, language: str) -> Dict:
        """Ø·Ù„Ø¨ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        context = self.build_chat_context(limit=3)
        context_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context])
        
        system_prompt = f"""
        You are a helpful Hajj verification assistant.
        Ask the user for more specific details if their question is vague.
        Respond in {language} ONLY.
        Return valid JSON with: needs_info, suggestions, missing_info, sample_query
        """
        
        try:
            prompt = f"{system_prompt}\nConversation Context:\n{context_text}\n\nUser's vague question: \"{user_input}\""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            info_data = json.loads(response.choices[0].message.content)
            
            return {
                "needs_info": info_data.get("needs_info", ""),
                "suggestions": info_data.get("suggestions", []),
                "missing_info": info_data.get("missing_info", []),
                "sample_query": info_data.get("sample_query", "")
            }
            
        except Exception as e:
            logger.error(f"More info prompt generation failed: {e}")
            is_arabic = language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
            return {
                "needs_info": "Could you provide more details? ğŸ¤”" if not is_arabic else "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ ğŸ¤”",
                "suggestions": ["Is Al Huda Hajj Agency authorized?"] if not is_arabic else ["Ù‡Ù„ Ø´Ø±ÙƒØ© Ø§Ù„Ù‡Ø¯Ù‰ Ù„Ù„Ø­Ø¬ Ù…Ø¹ØªÙ…Ø¯Ø©ØŸ"],
                "missing_info": ["agency name", "location"] if not is_arabic else ["Ø§Ø³Ù… Ø§Ù„ÙˆÙƒØ§Ù„Ø©", "Ø§Ù„Ù…ÙˆÙ‚Ø¹"],
                "sample_query": "Is Al Huda Hajj Agency authorized?" if not is_arabic else "Ù‡Ù„ Ø´Ø±ÙƒØ© Ø§Ù„Ù‡Ø¯Ù‰ Ù„Ù„Ø­Ø¬ Ù…Ø¹ØªÙ…Ø¯Ø©ØŸ"
            }
    
    def text_to_speech(self, text: str, language: str) -> Optional[io.BytesIO]:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)"""
        voice = self.voice_map.get(language, "alloy")
        try:
            response = self.client.audio.speech.create(
                model="tts-1",
                voice=voice,
                input=text,
                response_format="mp3"
            )
            audio_bytes = io.BytesIO(response.content)
            audio_bytes.seek(0)
            return audio_bytes
        except Exception as e:
            logger.error(f"TTS failed: {e}")
            return None
    
    def _detect_language_from_text(self, text: str) -> Optional[str]:
        """ÙƒØ´Ù Ø§Ù„Ù„ØºØ© Ù…Ù† Ø§Ù„Ù†Øµ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)"""
        if not text:
            return None
        
        arabic_chars = sum(1 for c in text if '\u0600' <= c <= '\u06FF')
        english_chars = sum(1 for c in text if c.isalpha() and c.isascii())
        
        total_chars = arabic_chars + english_chars
        if total_chars == 0:
            return None
        
        if arabic_chars / total_chars > 0.3:
            return "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
        else:
            return "English"
    
    @staticmethod
    def _get_sql_system_prompt(language: str) -> str:
        """Ù†Øµ SQL system prompt (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)"""
        return f"""
        You are a multilingual SQL fraud-prevention expert protecting Hajj pilgrims.
        Generate an SQL query for database analysis on Hajj agencies.
        Always return valid JSON with: sql_query, query_type, filters_applied, explanation, safety_checked
        
        TABLE STRUCTURE:
        - hajj_company_ar, hajj_company_en, formatted_address, city, country, email, 
        - contact_Info, rating_reviews, is_authorized, google_maps_link, link_valid
        
        Respond in {language} for explanations.
        """
    
    @staticmethod
    def _extract_sql_from_response(response_text: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ SQL Ù…Ù† Ø§Ù„Ø±Ø¯ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)"""
        if not response_text:
            return None
        
        code_block_pattern = r'```(?:sql)?\s*(SELECT[\s\S]*?)```'
        match = re.search(code_block_pattern, response_text, re.IGNORECASE)
        if match:
            return match.group(1).strip().rstrip(';')
        
        select_pattern = r'(SELECT\s+.*?(?:;|$))'
        match = re.search(select_pattern, response_text, re.IGNORECASE | re.DOTALL)
        if match:
            return match.group(1).strip().rstrip(';')
        if "NO_SQL" in response_text:
            return "NO_SQL"
        return None
